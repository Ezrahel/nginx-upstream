# Runbook — Blue/Green Observability & Alerts

This runbook describes alerts generated by the log-watcher and recommended operator actions.

Failover Detected
- What it means: The log-watcher observed the upstream `X-App-Pool` header switch from the previously active pool to the other pool (e.g., blue → green).
- Possible causes:
  - Primary app instance became unhealthy (5xxs or timeouts) and Nginx retried to backup
  - Network or container crash for the primary
- Immediate actions:
  1. Check Nginx and app container status:
     - `docker ps` / `docker compose ps`
     - `docker logs app_blue` / `docker logs app_green`
  2. Check Nginx access log sample included in the alert to find timestamps and upstream_status.
  3. Inspect the primary app's `/healthz` endpoint directly (e.g. `curl http://localhost:8081/healthz`).
  4. If primary is unhealthy, consider leaving traffic on backup and investigate the primary container logs. Restart primary if required.
- Recovery:
  - When primary becomes healthy again and you want it active, you may toggle `ACTIVE_POOL` and reload Nginx configuration, or manually switch by updating the env and running `docker compose up -d`.

High Upstream Error Rate
- What it means: Over the configured window (default 200 requests), the proportion of upstream responses with 5xx status exceeded the configured threshold (default 2%).
- Immediate actions:
  1. Confirm scope: are errors coming from one pool or both? Check Nginx access logs for `pool` and `upstream_status`.
  2. Inspect the corresponding app container logs for stack traces or resource issues.
  3. Check resource utilization on the host (`docker stats`, `top`, `free -m`) and network issues.
  4. Consider temporarily putting service into maintenance (`MAINTENANCE_MODE=true`) to suppress alerts during remediation.

Suppression / Maintenance Mode
- To suppress alerts during planned testing or deployments, set `MAINTENANCE_MODE=true` in `.env` and reload the watcher container (or restart the watcher service). This prevents Slack postings but preserves logging.

Alert Cooldown
- Alerts have a cooldown window (default 300s). Repeated identical alerts within the cooldown are suppressed to avoid spam.

Contacting Engineers
- Include the following when escalating to developers:
  - Timestamped sample log lines (included in the Slack alert)
  - Container logs from the timeframe
  - Host resource utilization

Notes
- The watcher only reads Nginx access logs and therefore is non-intrusive to application code.
- Keep `WINDOW_SIZE` and `ERROR_RATE_THRESHOLD` conservative to avoid false positives during brief spikes.
